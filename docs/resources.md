# Things to Read, Review, and Learn

- [ ] GNNs
- [ ] Attention
- [ ] LLMs
- [ ] Transformers
- [ ] Autoencoders
- [ ] RNNs
- [x] Basics
	- [x] Linear Algebra
	- [x] Probability
	- [x] Numerical Computation
	- [x] Training
 	- [x] Regularization


## Resources

## Classes

- [GNN Stanford](https://web.stanford.edu/class/cs224w/)
- [GNN Penn](https://gnn.seas.upenn.edu/)
- [Transformers, Hugging Face](https://huggingface.co/learn/nlp-course/chapter1/1)

## Topic Papers, Book Chapters, and Posts

* Graphical Neural Nets
	* [ ] [distill.pub](https://distill.pub/2021/gnn-intro/#graph-attention-networks)
- Attention
	- [x] [Machine Learning Mastery](https://machinelearningmastery.com/the-attention-mechanism-from-scratch/)
 	- [ ] [Machine Learning Mastery](https://machinelearningmastery.com/the-transformer-attention-mechanism/)
  	- [ ] [Lillian Weng](https://lilianweng.github.io/posts/2018-06-24-attention/)
- Generative Models
	- [ ] [Generative Adversarial Networks, Lillian Weng](https://lilianweng.github.io/posts/2017-08-20-gan/)
	- [ ] [Variational Auto Encoders, Lillian Weng](https://lilianweng.github.io/posts/2018-08-12-vae/)
	- [ ] [Deep Learning Book](https://www.deeplearningbook.org/contents/generative_models.html)
- Diffusion Models
	- [ ] [Lillian Weng](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/?utm_source=pocket_saves)
* Teacher Forcing
	* [ ] [Machine Learning Mastery](https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/)
* Attention and Augmented Recurrent Neural Networks
	* [ ] [distill.pub](https://distill.pub/2016/augmented-rnns/)
* Representation Learning
	* [ ] [Deep Learning Book](https://www.deeplearningbook.org/contents/representation.html)
* Transformers
	* [ ] [arxiv](https://arxiv.org/abs/2304.10557)
	* [ ] [Attention is All You Need, Arxiv](https://arxiv.org/pdf/1706.03762)
	* [x] [Google Research](https://blog.research.google/2017/08/transformer-novel-neural-network.html)
 	* [ ] [Wikipedia](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture))
  		* Actually good lmao 
* Protein Language Models
	* [ ] [Rives 2021, PNAS](https://www.pnas.org/doi/epdf/10.1073/pnas.2016239118)
	* [ ] [Lin 2023, ESM2, Science](https://www.science.org/doi/10.1126/science.ade2574)
 	* [ ] [Chen 2023, Xtrimo, Arxiv](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v3.full.pdf)
  	* [x] [Castro 2022, ReLSO, Nature](https://www.nature.com/articles/s42256-022-00532-1)
  	* [x] [Sun 2023, ÂµFormer, Arxiv](https://www.biorxiv.org/content/10.1101/2023.11.16.565910v2)
  		* [Notes](notes/muFormer.md) 	
* Autoencoders
	* [ ] [Deep Learning Book](https://www.deeplearningbook.org/contents/autoencoders.html)
* Basics
	* [ ] [Deep Learning Book](https://www.deeplearningbook.org/)
* General Topics
	* [ ] [ML for Protein Engineering, Arxiv](https://arxiv.org/abs/2305.16634)
